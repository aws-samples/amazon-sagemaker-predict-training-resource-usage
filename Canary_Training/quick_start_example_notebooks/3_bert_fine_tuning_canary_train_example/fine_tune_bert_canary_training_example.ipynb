{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "pretty-consideration",
   "metadata": {},
   "source": [
    "## Predict Training Time and SageMaker Training Instance RAM, CPU and GPU resource consumption for a Custom Script\n",
    "\n",
    "This notebook walks through how you can use the `canary_training` library to generate projections of training time, RAM, and CPU usage (collectivley refered to here as \"resource consumption\").\n",
    "\n",
    "To briefly summarize, the canary_training library works by creating many small training jobs on small percentages of the data (generally, 1,2 and 3 percent). Based on the statistics gathered (using the SageMaker Profiler) it then extrapolates the resource consumption for the complete training job.\n",
    "\n",
    "**Note** If you are using a SageMaker Notebook Instance, please use the `conda_python3` kernel. If you are using SageMaker Studio, please use `Python 3 (Data Science)` kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "incoming-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import pandas\n",
    "import logging\n",
    "logger = logging.getLogger('log')\n",
    "#set logs if not done already\n",
    "if not logger.handlers:\n",
    "    logger.setLevel(logging.INFO)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-reserve",
   "metadata": {},
   "source": [
    "This notebook relies on the `canary_training` package, which will be used for generating extrapolations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-record",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In SageMaker Studio\n",
    "!pip install ~/canary_training/Canary_Training/canary_training/\n",
    "#in a SageMaker Notebook Instance\n",
    "#!pip install /home/ec2-user/SageMaker/canary_training/Canary_Training/canary_training #make sure this points to the canary_training directory\n",
    "from canary_training import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-tradition",
   "metadata": {},
   "source": [
    "## Setup the Canary Job estimator and parameters\n",
    "Before using canary_training to generate predictions of resource consumption, we need to define a few things.\n",
    "\n",
    "1. A standard SageMaker estimator which defines our model.\n",
    "2. The instance(s) that we want to test.\n",
    "3. How many data points we want to make predictions based on.\n",
    "\n",
    "In this example, we will try to predict resource consumption (i.e. CPU, RAM, and training time) when training on a `ml.p2.xlarge`.\n",
    "\n",
    "This examples follows the [blog post](https://aws.amazon.com/blogs/machine-learning/fine-tuning-a-pytorch-bert-model-and-deploying-it-with-amazon-elastic-inference-on-amazon-sagemaker/) and associated Github resources to refine a BERT model using a custom script with Pytorch. The [associated dataset](https://nyu-mll.github.io/CoLA/) is 3 MB; which we partitioned to 200 csv files.\n",
    "\n",
    "In this notebook, we use the SageMaker XGBoost built-in algorithm to generate an ML model.\n",
    "\n",
    "**Note**: The dataset used for the ML model is located here: `s3://aws-hcls-ml/public_assets_support_materials/canary_training_data/cola_data/train_dir`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-commons",
   "metadata": {},
   "source": [
    "First we will set canary training configuration and options. We will be training on 1%,2% and 3% of the data in triplicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "steady-unknown",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from time import  gmtime,strftime\n",
    "import random\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.Session()\n",
    "output_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "instance_types=['ml.p2.xlarge'] #test on a GPU instance\n",
    "\n",
    "#set canary training parameters and inputs\n",
    "output_s3_location=f\"s3://{output_bucket}/bert_output_data\"\n",
    "#create a random local temporary directory which will be copied to s3\n",
    "#create a random local temporary directory which will be copied to s3\n",
    "#If this exists already, you can just point to it already\n",
    "random_number=random.randint(10000000, 99999999)\n",
    "the_temp_dir=f\"canary-training-temp-dir-{str(random_number)}\" \n",
    "\n",
    "training_percentages=[.01,.01,.01,.02,.02,.02,.03,.03,.03] #train jobs in triplicate in order to increase statistical confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "introductory-counter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-111918798052\n"
     ]
    }
   ],
   "source": [
    "print(output_bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-spring",
   "metadata": {},
   "source": [
    "Now we set standard SageMaker Estimator parameters. Because this is just a test, we use the same data for both the `training` and `test` channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eleven-commitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location='s3://aws-hcls-ml/public_assets_support_materials/canary_training_data/cola_data/train_dir' #location of input data for training\n",
    "\n",
    "# construct a SageMaker estimator that calls the xgboost-container\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"train_deploy.py\",\n",
    "    source_dir=\"code\",\n",
    "    role=role,\n",
    "    framework_version=\"1.4.0\",\n",
    "    py_version=\"py3\",\n",
    "    instance_count=1,  \n",
    "    instance_type=\"None\", #set instance type to None for now; it will be fille later by the canary training script\n",
    "    output_path=output_s3_location,\n",
    "    hyperparameters={\n",
    "        \"epochs\": 50,\n",
    "        \"num_labels\": 2,\n",
    "        \"backend\": \"gloo\",\n",
    "    },\n",
    "    disable_profiler=False, # disable debugger\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-commander",
   "metadata": {},
   "source": [
    "## Set up canary training jobs\n",
    "\n",
    "We will set up the canary training by:\n",
    "1. Creating samples of the underlying data\n",
    "2. Create manifest files that will be used for these smaller training jobs\n",
    "3. Copy the underlying manifest files to S3.\n",
    "4. Build estimators for SageMaker that will be used for these smaller training jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pregnant-projection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive canary-training-temp-dir-81739571 s3://sagemaker-us-east-1-111918798052/bert_output_data/canary-training-temp-dir-81739571/\n"
     ]
    }
   ],
   "source": [
    "ct=CanaryTraining(data_location=data_location,output_s3_location=output_s3_location,\n",
    "                           the_temp_dir=the_temp_dir,instance_types=instance_types,estimator=estimator,training_percentages=training_percentages)\n",
    "\n",
    "ct.prepare_canary_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logical-march",
   "metadata": {},
   "source": [
    "## Kick of canary training jobs\n",
    "Now that we have the list of estimators, let's kick off the canary training jobs.\n",
    "**Note**: By default, the canary_training library kicks off all of the jobs in parallel. For this example, this will mean that there will be 9 jobs on a `ml.p2.xlarge` running. If your account does not support this  many jobs of that instance type (and you cannot request an increase), you can run each job serially.\n",
    "\n",
    "If you run the jobs in parallel, the total amount of time taken is about 20 minutes. If you run them one-after-another, it takes about 2 hours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kick off in parallel\n",
    "ct.kick_off_canary_training_jobs(wait=True) #set wait equal to True, since we are using GPU instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-broad",
   "metadata": {},
   "source": [
    "# Wait until the jobs are finished before continuing in the next section!!!\n",
    "Before continuing, please make sure that all the jobs kicked off for canary training are finished. You can see these jobs in the `SageMake Training` console. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-twelve",
   "metadata": {},
   "source": [
    "# Gather Statistics and Perform Extrapolations\n",
    "\n",
    "In the next section we will gather statistics around the training jobs, and use them to **extrapolate** resource consumption for the entire training job. We will do three things:\n",
    "\n",
    "1. Extract relevant information from the training job and the SageMaker Profiler around CPU, RAM, GPU and Training Time.\n",
    "2. Report the extrapolated CPU usage, RAM, GPU and Training Time and cost.\n",
    "3. Report the raw CPU usage, RAM, GPU and Training Time for the canary training jobs themselves. This will allow the user to make an informed decision based on this detailed information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "geological-pursuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "#submitted_jobs_information\n",
    "predicted_resource_usage_df,raw_actual_resource_usage_df=ct.get_predicted_resource_consumption()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "environmental-senegal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Projected_CPUUtilization</th>\n",
       "      <th>Projected_MemoryUsedPercent</th>\n",
       "      <th>Projected_TrainingTimeInSeconds</th>\n",
       "      <th>Projected_GPUUtilization</th>\n",
       "      <th>Projected_GPUMemoryUtilization</th>\n",
       "      <th>price</th>\n",
       "      <th>Projected_TotalCost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ml.p2.xlarge</th>\n",
       "      <td>27.5</td>\n",
       "      <td>5.159929</td>\n",
       "      <td>21504.810337</td>\n",
       "      <td>110.0</td>\n",
       "      <td>59.401159</td>\n",
       "      <td>0.0003125</td>\n",
       "      <td>6.72025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Projected_CPUUtilization  Projected_MemoryUsedPercent  \\\n",
       "ml.p2.xlarge                      27.5                     5.159929   \n",
       "\n",
       "              Projected_TrainingTimeInSeconds  Projected_GPUUtilization  \\\n",
       "ml.p2.xlarge                     21504.810337                     110.0   \n",
       "\n",
       "              Projected_GPUMemoryUtilization      price Projected_TotalCost  \n",
       "ml.p2.xlarge                       59.401159  0.0003125             6.72025  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_resource_usage_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-aging",
   "metadata": {},
   "source": [
    "Now report the raw info from the canary jobs. \n",
    "\n",
    "**Note** that the `PercentageDataTrainedOn` column does not exactly match the 1,2 and 3 percentages due to those numbers not evenly dividing into the number of partitions of the data (200 partitions)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-specialist",
   "metadata": {},
   "source": [
    "# Inspect Canary Training Job Results\n",
    "You can inspect the underlying data for the canary training results. This is the data that was used to create the forcasts. While the forecasts may be useful, we strongly encourage data scientists to inspect the raw results as well. Note that CPUUtilization,MemoryUsedPercent,GPUUtilization,and GPUMemoryUtilization are all p99 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "thousand-pontiac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>TrainingTimeInSeconds</th>\n",
       "      <th>InstanceType</th>\n",
       "      <th>ManifestLocation</th>\n",
       "      <th>job_name</th>\n",
       "      <th>PercentageDataTrainedOn</th>\n",
       "      <th>CPUUtilization</th>\n",
       "      <th>I/OWaitPercentage</th>\n",
       "      <th>MemoryUsedPercent</th>\n",
       "      <th>GPUUtilization</th>\n",
       "      <th>GPUMemoryUtilization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Completed</td>\n",
       "      <td>348</td>\n",
       "      <td>ml.p2.xlarge</td>\n",
       "      <td>s3://sagemaker-us-east-1-111918798052/bert_out...</td>\n",
       "      <td>canary-training--job-2022-03-22-14-51-04-03417...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>25.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>4.7200</td>\n",
       "      <td>100.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Completed</td>\n",
       "      <td>429</td>\n",
       "      <td>ml.p2.xlarge</td>\n",
       "      <td>s3://sagemaker-us-east-1-111918798052/bert_out...</td>\n",
       "      <td>canary-training--job-2022-03-22-15-01-05-05249...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>25.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>4.7000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stopped</td>\n",
       "      <td>1</td>\n",
       "      <td>ml.p2.xlarge</td>\n",
       "      <td>s3://sagemaker-us-east-1-111918798052/bert_out...</td>\n",
       "      <td>canary-training--job-2022-03-22-15-10-56-07184...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>25.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>4.7000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Completed</td>\n",
       "      <td>509</td>\n",
       "      <td>ml.p2.xlarge</td>\n",
       "      <td>s3://sagemaker-us-east-1-111918798052/bert_out...</td>\n",
       "      <td>canary-training--job-2022-03-22-15-13-08-05118...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>25.0</td>\n",
       "      <td>98.00</td>\n",
       "      <td>4.6938</td>\n",
       "      <td>100.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Completed</td>\n",
       "      <td>504</td>\n",
       "      <td>ml.p2.xlarge</td>\n",
       "      <td>s3://sagemaker-us-east-1-111918798052/bert_out...</td>\n",
       "      <td>canary-training--job-2022-03-22-15-23-58-05594...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>25.0</td>\n",
       "      <td>97.96</td>\n",
       "      <td>4.6900</td>\n",
       "      <td>100.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TrainingJobStatus  TrainingTimeInSeconds  InstanceType  \\\n",
       "0         Completed                    348  ml.p2.xlarge   \n",
       "1         Completed                    429  ml.p2.xlarge   \n",
       "2           Stopped                      1  ml.p2.xlarge   \n",
       "3         Completed                    509  ml.p2.xlarge   \n",
       "4         Completed                    504  ml.p2.xlarge   \n",
       "\n",
       "                                    ManifestLocation  \\\n",
       "0  s3://sagemaker-us-east-1-111918798052/bert_out...   \n",
       "1  s3://sagemaker-us-east-1-111918798052/bert_out...   \n",
       "2  s3://sagemaker-us-east-1-111918798052/bert_out...   \n",
       "3  s3://sagemaker-us-east-1-111918798052/bert_out...   \n",
       "4  s3://sagemaker-us-east-1-111918798052/bert_out...   \n",
       "\n",
       "                                            job_name PercentageDataTrainedOn  \\\n",
       "0  canary-training--job-2022-03-22-14-51-04-03417...                    0.01   \n",
       "1  canary-training--job-2022-03-22-15-01-05-05249...                    0.01   \n",
       "2  canary-training--job-2022-03-22-15-10-56-07184...                    0.01   \n",
       "3  canary-training--job-2022-03-22-15-13-08-05118...                    0.02   \n",
       "4  canary-training--job-2022-03-22-15-23-58-05594...                    0.02   \n",
       "\n",
       "   CPUUtilization  I/OWaitPercentage  MemoryUsedPercent  GPUUtilization  \\\n",
       "0            25.0             100.00             4.7200           100.0   \n",
       "1            25.0             100.00             4.7000           100.0   \n",
       "2            25.0             100.00             4.7000           100.0   \n",
       "3            25.0              98.00             4.6938           100.0   \n",
       "4            25.0              97.96             4.6900           100.0   \n",
       "\n",
       "   GPUMemoryUtilization  \n",
       "0                  55.0  \n",
       "1                  54.0  \n",
       "2                  54.0  \n",
       "3                  54.0  \n",
       "4                  54.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_actual_resource_usage_df.head()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.xlarge",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
